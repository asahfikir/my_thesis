% Awal mulai AI Boom
@misc{vaswani2023attentionneed,
      title={Attention Is All You Need},
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762},
}

% Cara kerja AI, kenapa chunking dll itu penting
@misc{liu2023lostmiddlelanguagemodels,
      title={Lost in the Middle: How Language Models Use Long Contexts},
      author={Nelson F. Liu and Kevin Lin and John Hewitt and Ashwin Paranjape and Michele Bevilacqua and Fabio Petroni and Percy Liang},
      year={2023},
      eprint={2307.03172},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.03172},
}

@article{Liu2023LostIT,
  title={Lost in the Middle: How Language Models Use Long Contexts},
  author={Nelson F. Liu and Kevin Lin and John Hewitt and Ashwin Paranjape and Michele Bevilacqua and Fabio Petroni and Percy Liang},
  journal={Transactions of the Association for Computational Linguistics},
  year={2023},
  volume={12},
  pages={157-173},
  url={https://api.semanticscholar.org/CorpusID:259360665}
}

% Highlight problem akurasi pada baseline RAG
@misc{edge2025localglobalgraphrag,
      title={From Local to Global: A Graph RAG Approach to Query-Focused Summarization},
      author={Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Dasha Metropolitansky and Robert Osazuwa Ness and Jonathan Larson},
      year={2025},
      eprint={2404.16130},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.16130},
}

% Paper ini mempopulerkan penggunaan metrik faithfulness dan answer relevance (yang melibatkan kesamaan vektor/cosine similarity)
@misc{es2025ragasautomatedevaluationretrieval,
      title={Ragas: Automated Evaluation of Retrieval Augmented Generation},
      author={Shahul Es and Jithin James and Luis Espinosa-Anke and Steven Schockaert},
      year={2025},
      eprint={2309.15217},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.15217},
}

% Menunjukkan bahwa rata-rata penelitian hanya menggunakan LLM besar bukan SLM
@misc{xu2024activecellbalancingextended,
      title={Active Cell Balancing for Extended Operational Time of Lithium-Ion Battery Systems in Energy Storage Applications},
      author={Yiming Xu and Xiaohua Ge and Ruohan Guo and Weixiang Shen},
      year={2024},
      eprint={2405.00973},
      archivePrefix={arXiv},
      primaryClass={eess.SY},
      url={https://arxiv.org/abs/2405.00973},
}

@inproceedings{shen2024small,
  title={Small LLMs Are Weak Tool Learners: A Multi-LLM Agent},
  author={Shen, Weizhou and Li, Chenliang and Chen, Hongzhan and Yan, Ming and Quan, Xiaojun and Chen, Hehong and Zhang, Ji and Huang, Fei},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={16658--16680},
  year={2024}
}

@article{hu2024llm,
  title={LLM vs Small Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model},
  author={Hu, Linmei and He, Hongyu and Wang, Duokang and Zhao, Ziwang and Shao, Yingxia and Nie, Liqiang},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-24)},
  volume={38},
  year={2024}
}

@article{tsaneva2025knowledge,
  title={Knowledge graph validation by integrating LLMs and human-in-the-loop},
  author={Tsaneva, Stefani and Dess{\`\i}, Danilo and Osborne, Francesco and Sabou, Marta},
  journal={Information Processing and Management},
  volume={62},
  number={104145},
  year={2025},
  publisher={Elsevier}
}

@article{topal2025predicting,
  title={Predicting equine behavior from small datasets using machine learning with LLM-generated explanations},
  author={Topal, Oleksandra and Novalija, Inna and Mladeni{\'c}, Dunja and Gobbo, Elena and {\v{S}}emrov, Manja Zupan},
  journal={Applied Animal Behaviour Science},
  volume={293},
  number={106863},
  year={2025},
  publisher={Elsevier}
}

@article{cahyawijaya2024cendol,
  title={Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages},
  author={Cahyawijaya, Samuel and Lovenia, Holy and Koto, Fajri and Putri, Rifki Afina and Dave, Emmanuel and others},
  journal={arXiv preprint},
  year={2024}
}

@article{hong2025innovative,
  title={Innovative Applications of RAG-enhanced Small LLM for Closed-Domain Q\&A},
  author={Hong, Youngpyo and Kim, Dongsoo},
  journal={International Journal of Innovative Computing, Information and Control (IJICIC)},
  volume={21},
  number={2},
  pages={481--490},
  year={2025}
}

@article{liu2023lost,
  title={Lost in the Middle: How Language Models Use Long Contexts},
  author={Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics (TACL)},
  year={2023}
}

@article{lee2024logic,
  title={LOGIC: LLM-originated guidance for internal cognitive improvement of small language models in stance detection},
  author={Lee, Woojin and Lee, Jaewook and Kim, Harksoo},
  journal={PeerJ Computer Science},
  volume={10},
  number={e2585},
  year={2024},
  publisher={PeerJ Inc.}
}

@article{es2023ragas,
  title={Ragas: Automated Evaluation of Retrieval Augmented Generation},
  author={Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  journal={arXiv preprint arXiv:2309.15217},
  year={2023}
}

@article{wang2025reinforcement,
  title={Reinforcement learning for LLM-based explainable TCM prescription recommendation with implicit preferences from small language models},
  author={Wang, Xinyu and Sun, Xiaohe and Yang, Lei and Zhang, Yitong and Yang, Tao and Xie, Jiadong and Hu, Kongfa},
  journal={Chinese Medicine},
  volume={20},
  number={193},
  year={2025},
  publisher={Springer Nature}
}

@article{ng2025sealion,
  title={SEA-LION: Southeast Asian Languages in One Network},
  author={Ng, Raymond and Nguyen, Thanh Ngan and Huang, Yuli and Tai, Ngee Chia and Leong, Wai Yi and others},
  journal={Preprint},
  year={2025}
}
